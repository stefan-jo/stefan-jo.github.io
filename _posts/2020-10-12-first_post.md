# NLP Summit 2020

[Note: This blog post is work in progress]

I want to kick off this blog by describing my impressions and take-aways from attending the [NLP Summit 2020: Applied Natural Language Processing](https://www.nlpsummit.org/) which took place virtually between October 6th and 9th. [John Snow Labs](https://www.johnsnowlabs.com/), the main creator behind [Spark NLP](https://github.com/JohnSnowLabs/spark-nlp) and organizer of the summit put together a diverse and interesting program for the four conference days.

Overall I really enjoyed the conference. I especially liked the focus on *applied* NLP, presenting many specific NLP use cases from industry as well as topics such as product management, model deployment and data annotation. Working myself at the intersection of applied NLP research, data science and engineering, I recognized many common pain points and lessons learned from my own experience during the conference. Please note that this blog post only describes my own experience and doesn't give a full picture of the conference. Even though I tried to attend as many sessions as possible, I am sure that I still missed some great talks. 

I will divide this blog post into four sections:
1. The state of Applied NLP in 2020
2. The importance of data annotation
3. Three personal highlights
4. My hackathon solution

## 1. The state of Applied NLP in 2020

The field of applied NLP has made tremendous progress over the last couple of years and continues to grow. Not only are academic benchmarks being beaten at a regular rate, but companies are also increasingly applying these new technologies to their use cases. One of the best indicators for the growing importance of NLP for businesses are the budgets dedicated to the field. Taken from the [*2020 NLP Survey Report*](https://gradientflow.com/2020nlpsurvey/) by Ben Lorica and Paco Nathan, 53%/31% of technical leaders reported that their NLP budget was at least 10%/31% higher in 2020 relative to 2019. 

When it comes to specific use cases, document classification, named entity recognition and sentiment analysis are still the most popular NLP tasks. Given the sheer amount of text documents that companies are processing on a daily basis and the recent rate of improvement of NLP techniques, I believe that we will see an enourmous demand for NLP tools, platforms, engineers and researchers in the coming years. Cl√©ment Delangue, CEO at huggingface, even went so far as giving a keynote titled "NLP is going to be the most transformational tech of the decade!", basing this claim on the fact that most of our day, both at work and in private, is spent using natural language, which finally can be  accurately processed by machines thanks to recent improvements. 

Just to mention a few of the many exciting use cases that were presented at the conference: 
- automated de-identification of medial records to enable the processing of sensitive documents such as in healthcare
- above-human-level-performance document classification and *abstractive* (!) summarization of documents in the legal domain
- using a combination of ML-powered text classification and rule-based programs to build effective chatbots

Tools:
- Which tools are around? 
- Which libraries are most used?
- Off the shelve tools don't work. Still need to train or fine-tune on custom data

## 2. The importance of data annotation

- Multiple labelers, consensus
- Alignment sessions with team and clients
- Define and review clear annotation guidelines
- Use domain experts for annotation!
- Use annotation tools! Prodigy or in-house
- Aim for high IAA (Inter annotator agreement)

## 3. Three personal highlights

- Joel Grus (Principal Engineer @ Capital Group): Proof-of-concept delight
- Christine Gerpheide (CTO @ Bespoke): NLP research to production
- Moshe Wasserblat (NLP & DL Research Manager @ Intel): Efficient DL NLP in production

## 4. My hackathon solution

- Describe challenge and my solution
- Post link to solution on github



